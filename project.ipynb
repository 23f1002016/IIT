{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "\n",
    "token = \"*****\"\n",
    "headers = {'Authorization': f'token {token}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_company_name(company):\n",
    "    if company:\n",
    "        company = company.strip()\n",
    "        if company.startswith(\"@\"):\n",
    "            company = company[1:]\n",
    "        return company.upper()\n",
    "    return \"\"\n",
    "\n",
    "def fetch_seattle_users(min_followers=200):\n",
    "    users = []\n",
    "    url = \"https://api.github.com/search/users\"\n",
    "    page = 1\n",
    "\n",
    "   \n",
    "    while len(users) < 518: \n",
    "        params = {\n",
    "            \"q\": f\"location:Seattle followers:>{min_followers}\",\n",
    "            \"per_page\": 100,\n",
    "            \"page\": page\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error: {response.json()}\")\n",
    "            break\n",
    "        \n",
    "        data = response.json()\n",
    "        for user in data.get('items', []):\n",
    "            user_detail = requests.get(user['url'], headers=headers).json()\n",
    "            if user_detail.get(\"followers\", 0) > min_followers:\n",
    "                users.append({\n",
    "                    \"login\": user_detail.get(\"login\", \"\"),\n",
    "                    \"name\": user_detail.get(\"name\", \"\"),\n",
    "                    \"company\": clean_company_name(user_detail.get(\"company\", \"\")),\n",
    "                    \"location\": user_detail.get(\"location\", \"\"),\n",
    "                    \"email\": user_detail.get(\"email\", \"\"),\n",
    "                    \"hireable\": user_detail.get(\"hireable\", \"\"),\n",
    "                    \"bio\": user_detail.get(\"bio\", \"\"),\n",
    "                    \"public_repos\": user_detail.get(\"public_repos\", 0),\n",
    "                    \"followers\": user_detail.get(\"followers\", 0),\n",
    "                    \"following\": user_detail.get(\"following\", 0),\n",
    "                    \"created_at\": user_detail.get(\"created_at\", \"\")\n",
    "                })\n",
    "    \n",
    "        if len(data['items']) == 0:\n",
    "            break\n",
    "\n",
    "        page += 1\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return users[:518]\n",
    "\n",
    "users_data = fetch_seattle_users()\n",
    "users_df = pd.DataFrame(users_data)\n",
    "users_df.to_csv(\"users.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_user_repositories(login):\n",
    "    repos = []\n",
    "    url = f\"https://api.github.com/users/{login}/repos\"\n",
    "    page = 1\n",
    "\n",
    "    while len(repos) < 500:\n",
    "        params = {\n",
    "            \"per_page\": 100,\n",
    "            \"page\": page,\n",
    "            \"sort\": \"pushed\"\n",
    "        }\n",
    "        response = requests.get(url, headers=headers, params=params)\n",
    "        \n",
    "        if response.status_code != 200:\n",
    "            print(f\"Error fetching repos for {login}: {response.json()}\")\n",
    "            break\n",
    "        \n",
    "        data = response.json()\n",
    "        if len(data) == 0:\n",
    "            break  \n",
    "        \n",
    "        for repo in data:\n",
    "            repos.append({\n",
    "                \"login\": login,\n",
    "                \"full_name\": repo.get(\"full_name\", \"\"),\n",
    "                \"created_at\": repo.get(\"created_at\", \"\"),\n",
    "                \"stargazers_count\": repo.get(\"stargazers_count\", 0),\n",
    "                \"watchers_count\": repo.get(\"watchers_count\", 0),\n",
    "                \"language\": repo.get(\"language\", \"\"),\n",
    "                \"has_projects\": repo.get(\"has_projects\", False),\n",
    "                \"has_wiki\": repo.get(\"has_wiki\", False),\n",
    "                \"license_name\": repo.get(\"license\", {}).get(\"key\", \"\") if repo.get(\"license\") else \"\"\n",
    "            })\n",
    "        page += 1\n",
    "        time.sleep(1) \n",
    "    \n",
    "    return repos[:500] \n",
    "\n",
    "users_df = pd.read_csv(\"users.csv\")\n",
    "all_repositories = []\n",
    "\n",
    "for login in users_df['login']:\n",
    "    user_repos = fetch_user_repositories(login)\n",
    "    all_repositories.extend(user_repos)\n",
    "    print(f\"Fetched {len(user_repos)} repositories for user {login}\")\n",
    "\n",
    "repositories_df = pd.DataFrame(all_repositories)\n",
    "repositories_df.to_csv(\"repositories.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_df = pd.read_csv(\"users.csv\")\n",
    "repos_df = pd.read_csv(\"repositories.csv\")\n",
    "\n",
    "# Question 1\n",
    "top_followers = users_df.sort_values(by=\"followers\", ascending=False).head(5)\n",
    "top_followers_logins = \", \".join(top_followers[\"login\"].tolist())\n",
    "print(\"Top 5 users by followers:\", top_followers_logins)\n",
    "\n",
    "# Question 2\n",
    "earliest_users = users_df.sort_values(by=\"created_at\").head(5)\n",
    "earliest_users_logins = \", \".join(earliest_users[\"login\"].tolist())\n",
    "print(\"Earliest registered users:\", earliest_users_logins)\n",
    "\n",
    "# Question 3\n",
    "top_licenses = repos_df[\"license_name\"].value_counts().head(3).index.tolist()\n",
    "print(\"Top 3 licenses:\", \", \".join(top_licenses))\n",
    "\n",
    "# Question 4\n",
    "top_company = users_df[\"company\"].mode()[0]\n",
    "print(\"Most common company:\", top_company)\n",
    "\n",
    "# Question 5\n",
    "top_language = repos_df[\"language\"].mode()[0]\n",
    "print(\"Most popular language:\", top_language)\n",
    "\n",
    "# Question 6\n",
    "recent_users = users_df[users_df[\"created_at\"] > \"2020-01-01\"][\"login\"]\n",
    "recent_repos = repos_df[repos_df[\"login\"].isin(recent_users)]\n",
    "second_language = recent_repos[\"language\"].value_counts().index[1]\n",
    "print(\"Second most popular language (after 2020):\", second_language)\n",
    "\n",
    "# Question 7\n",
    "language_stars = repos_df.groupby(\"language\")[\"stargazers_count\"].mean()\n",
    "top_star_language = language_stars.idxmax()\n",
    "print(\"Language with highest average stars:\", top_star_language)\n",
    "\n",
    "# Question 8\n",
    "users_df[\"leader_strength\"] = users_df[\"followers\"] / (1 + users_df[\"following\"])\n",
    "top_leader_strength = users_df.sort_values(by=\"leader_strength\", ascending=False).head(5)[\"login\"]\n",
    "print(\"Top 5 by leader strength:\", \", \".join(top_leader_strength))\n",
    "\n",
    "# Question 9\n",
    "correlation_followers_repos = users_df[\"followers\"].corr(users_df[\"public_repos\"])\n",
    "print(\"Correlation between followers and public repos:\", round(correlation_followers_repos, 3))\n",
    "\n",
    "# Question 10\n",
    "from scipy.stats import linregress\n",
    "slope, _, _, _, _ = linregress(users_df[\"public_repos\"], users_df[\"followers\"])\n",
    "print(\"Followers per additional repo (slope):\", round(slope, 3))\n",
    "\n",
    "# Question 11\n",
    "correlation_projects_wiki = repos_df[\"has_projects\"].corr(repos_df[\"has_wiki\"])\n",
    "print(\"Correlation between projects and wiki enabled:\", round(correlation_projects_wiki, 3))\n",
    "\n",
    "# Question 12\n",
    "avg_following_hireable = users_df[users_df[\"hireable\"] == True][\"following\"].mean()\n",
    "avg_following_nonhireable = users_df[users_df[\"hireable\"] == False][\"following\"].mean()\n",
    "following_difference = avg_following_hireable - avg_following_nonhireable\n",
    "print(\"Difference in average following (hireable vs non-hireable):\", round(following_difference, 3))\n",
    "\n",
    "# Question 13\n",
    "users_df['bio'] = users_df['bio'].fillna('')\n",
    "users_df['followers'] = users_df['followers'].fillna(0)  \n",
    "users_df['bio_word_count'] = users_df['bio'].apply(lambda x: len(x.split()))\n",
    "filtered_df = users_df[users_df['bio_word_count'] > 0]\n",
    "X = filtered_df['bio_word_count'] \n",
    "y = filtered_df['followers'] \n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(y, X).fit()\n",
    "slope = model.params['bio_word_count']\n",
    "print(\"Regression slope of followers on bio word count:\", round(slope, 3))\n",
    "\n",
    "\n",
    "# Question 14\n",
    "repos_df[\"created_at\"] = pd.to_datetime(repos_df[\"created_at\"])\n",
    "repos_df[\"is_weekend\"] = repos_df[\"created_at\"].dt.dayofweek >= 5\n",
    "weekend_creators = repos_df[repos_df[\"is_weekend\"]].groupby(\"login\").size().nlargest(5).index.tolist()\n",
    "print(\"Top 5 weekend creators:\", \", \".join(weekend_creators))\n",
    "\n",
    "# Question 15 -- however, this was solved in microsoft excel using simple formulae\n",
    "def analyze_email_and_hireable(df):\n",
    "    df['email'].fillna('', inplace=True)\n",
    "    df['hireable'].fillna(False, inplace=True)\n",
    "    df['hireable'] = df['hireable'].astype(bool)\n",
    "    fraction_hireable_with_email = df[df['hireable']]['email'].astype(bool).mean()\n",
    "    fraction_non_hireable_with_email = df[~df['hireable']]['email'].astype(bool).mean()\n",
    "    return fraction_hireable_with_email, fraction_non_hireable_with_email\n",
    "df = pd.read_csv('users.csv')\n",
    "fraction_hireable, fraction_non_hireable = analyze_email_and_hireable(df)\n",
    "print(\"Fraction of hireable users with email:\", fraction_hireable)\n",
    "print(\"Fraction of non-hireable users with email:\", fraction_non_hireable)\n",
    "print(\"Difference in email sharing (hireable vs non-hireable):\", fraction_hireable - fraction_non_hireable)\n",
    "\n",
    "# Question 16\n",
    "users_df['surname'] = users_df['name'].dropna().apply(lambda x: x.strip().split()[-1])\n",
    "surname_counts = users_df['surname'].value_counts()\n",
    "max_count = surname_counts.max()\n",
    "most_common_surnames = surname_counts[surname_counts == max_count].index.tolist()\n",
    "print(\"The most common surname is:\", ','.join(sorted(most_common_surnames)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
